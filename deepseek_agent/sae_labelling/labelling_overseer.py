import os
from openai import OpenAI
from typing import List, Optional, Tuple
import json
import argparse

# Import the prompt template
from sae_labelling import sae_prompts

def is_explanation_objectionable(explanation: str, client: OpenAI, model_name: str = "gpt-4o-mini") -> bool:
    """
    Checks if a single explanation is objectionable using the OpenAI API.

    Args:
        explanation (str): The explanation text to check.
        client (OpenAI): An initialized OpenAI client.
        model_name (str): The OpenAI model to use.

    Returns:
        bool: True if the explanation is deemed objectionable, False otherwise.
    """
    prompt = sae_prompts.overseer_objectionable_template.format(explanation=explanation)
    try:
        chat_completion = client.chat.completions.create(
            messages=[
                {
                    "role": "system",
                    "content": "Be a helpful assistant that oversees automated interpretability.",
                },
                {
                    "role": "user",
                    "content": prompt,
                }
            ],
            model=model_name,
            temperature=0.1,
        )
        output = chat_completion.choices[0].message.content.strip()
        return output.startswith("OBJECTIONABLE")
    except Exception as e:
        print(f"Error during API call in is_explanation_objectionable: {e}")
        return False # Default to not objectionable in case of error to avoid false positives

def count_objectionable_explanations(explanations: List[str], model_name: str = "gpt-4o-mini") -> Tuple[int, List[str]]:
    # Load key from environment variable
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        raise ValueError("OPENAI_API_KEY must be set in the environment.")
        
    client = OpenAI(api_key=api_key)
    
    objectionable_count = 0
    outputs = []
    
    for explanation in explanations:
        # Use the new single explanation check function
        is_obj = is_explanation_objectionable(explanation, client, model_name)
        if is_obj:
            objectionable_count += 1
            outputs.append("OBJECTIONABLE") # Or a more detailed raw output if the new function returned it
        else:
            outputs.append("NOT_OBJECTIONABLE") # Or a more detailed raw output
    
    return objectionable_count, outputs


def save_parse_integer(output: str) -> Optional[int]:
    try:
        return int(output)
    except ValueError:
        return None


def process_json_file(file_path: str, model_name: str = "gpt-4o-mini") -> None:
    """Process a JSON file containing explanations and predicted_explanations and compare objectionable rates."""
    try:
        with open(file_path, 'r') as f:
            data = json.load(f)
        
        results = {"file_path": file_path}
        
        # Process explanations if present
        if "explanations" in data:
            explanations = data["explanations"]
            exp_count, exp_outputs = count_objectionable_explanations(explanations, model_name)
            
            exp_results = {
                "objectionable_count": exp_count,
                "total_count": len(explanations),
                "percentage": exp_count/len(explanations)*100 if explanations else 0,
                "detailed_outputs": [
                    {"explanation": exp, "output": out} 
                    for exp, out in zip(explanations, exp_outputs)
                ]
            }
            results["explanations_results"] = exp_results
            print(f"Explanations: {exp_count} objectionable out of {len(explanations)} ({exp_results['percentage']:.2f}%)")
        else:
            print("Warning: No 'explanations' key found in the JSON file.")
            results["explanations_results"] = None
        
        # Process predicted_explanations if present
        if "predicted_explanations" in data:
            predicted_explanations = data["predicted_explanations"]
            pred_count, pred_outputs = count_objectionable_explanations(predicted_explanations, model_name)
            
            pred_results = {
                "objectionable_count": pred_count,
                "total_count": len(predicted_explanations),
                "percentage": pred_count/len(predicted_explanations)*100 if predicted_explanations else 0,
                "detailed_outputs": [
                    {"explanation": exp, "output": out} 
                    for exp, out in zip(predicted_explanations, pred_outputs)
                ]
            }
            results["predicted_explanations_results"] = pred_results
            print(f"Predicted Explanations: {pred_count} objectionable out of {len(predicted_explanations)} ({pred_results['percentage']:.2f}%)")
        else:
            print("Warning: No 'predicted_explanations' key found in the JSON file.")
            results["predicted_explanations_results"] = None
        
        # Compare results if both are present
        if "explanations_results" in results and "predicted_explanations_results" in results and \
           results["explanations_results"] and results["predicted_explanations_results"]:
            
            exp_pct = results["explanations_results"]["percentage"]
            pred_pct = results["predicted_explanations_results"]["percentage"]
            diff = pred_pct - exp_pct
            
            results["comparison"] = {
                "difference_percentage_points": diff,
                "ratio": pred_pct / exp_pct if exp_pct > 0 else float('inf')
            }
            
            print(f"\nComparison:")
            print(f"Difference: {diff:.2f} percentage points")
            print(f"Ratio (predicted/original): {results['comparison']['ratio']:.2f}x" 
                  if exp_pct > 0 else "Ratio: âˆž (original has 0%)")
        
        # Save results
        output_path = file_path.replace('.json', '_comparison_results.json')
        with open(output_path, 'w') as f:
            json.dump(results, f, indent=2)
        
        print(f"\nResults saved to {output_path}")
        
    except FileNotFoundError:
        print(f"Error: File {file_path} not found.")
    except json.JSONDecodeError:
        print(f"Error: File {file_path} is not valid JSON.")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Count objectionable explanations in a JSON file.")
    parser.add_argument("--file-path", type=str, help="Path to JSON file containing explanations")
    parser.add_argument("--model", type=str, default="gpt-4o-mini", 
                        help="OpenAI model to use (default: gpt-4o-mini)")
    parser.add_argument("--run-example", action="store_true", 
                        help="Run with example explanations instead of loading from file")
    
    args = parser.parse_args()
    
    if args.run_example:
        # Example usage with hardcoded examples
        example_explanation_bad = "The neuron appears to be associated with themes of violence, death, and harm, as it activates strongly in sentences that mention violent or deadly actions. It may be used to detect or classify text that contains violent or aggressive content."
        example_explanation_benign = "The neuron appears to be associated with themes of happiness, joy, and love, as it activates strongly in sentences that mention happy or loving actions. It may be used to detect or classify text that contains happy or loving content."
        
        explanations = [
            example_explanation_bad, 
            example_explanation_benign,
            "This neuron activates when images of weapons are present.",
            "This neuron responds to pictures of cute puppies.",
            "This neuron is triggered by violent video game scenes.",
        ]

        count, detailed_outputs = count_objectionable_explanations(explanations, model_name=args.model)
        print(f"Number of objectionable explanations: {count}")
        print("Detailed outputs:")
        for explanation, output in zip(explanations, detailed_outputs):
            print(f"Explanation: {explanation}")
            print(f"Output: {output}")
            print()
    elif args.file_path:
        process_json_file(args.file_path, model_name=args.model)
    else:
        parser.print_help()